{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find clusters of diabetes patients \n",
    "\n",
    "Utilizing Pima Indians Diabetes Database from kaggle, utilize suprvised learning KNN model to find clusters of diabetes patients based on various input features from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.292</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>716</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>185</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.970</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>563</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.497</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.645</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>5</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>160</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.361</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "491            2       89             90             30        0  33.5   \n",
       "716            3      173             78             39      185  33.8   \n",
       "563            6       99             60             19       54  26.9   \n",
       "230            4      142             86              0        0  44.0   \n",
       "189            5      139             80             35      160  31.6   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "491                     0.292   42        0  \n",
       "716                     0.970   31        1  \n",
       "563                     0.497   32        0  \n",
       "230                     0.645   22        1  \n",
       "189                     0.361   25        1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read diabetes dataset\n",
    "input_data_path = '/Users/mmichalski/dev/ml/scikit-projects/data/diabetes.csv'\n",
    "df = pd.read_csv(input_data_path)\n",
    "\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data frame dropping outcome column that specifies if a patient has diebetes\n",
    "X = df.drop(columns=['Outcome'])\n",
    "X.head(5)\n",
    "\n",
    "# define the target variable data\n",
    "y = df['Outcome'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train/test into 80/20 size and stratify the training outcome data by 25/75\n",
    "# 25% that have diabetes and 75% that don't \n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the Knearest neighbors classifier to the data\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the prediction on test data set of first 5 records\n",
    "knn.predict(X_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6688311688311688\n"
     ]
    }
   ],
   "source": [
    "# measure the accuracy of the model\n",
    "\n",
    "test_acc = knn.score(X_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68181818 0.69480519 0.75324675 0.75163399 0.68627451]\n",
      "cv_scores mean:0.7135557253204311\n"
     ]
    }
   ],
   "source": [
    "# Add k-fold (5 fold) cross validation to determine a mean score and see how the\n",
    "# model will perform in the wild on the onseen data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "\n",
    "#print each cv score (accuracy) and average them\n",
    "print(cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid searching through following parameters: {'n_neighbors': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33]), 'metric': ['euclidean', 'manhattan', 'minkowski']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmichalski/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] grid search took 1.75 seconds\n",
      "[INFO] grid search accuracy: 77.92%\n",
      "[INFO] grid search best parameters: {'metric': 'manhattan', 'n_neighbors': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmichalski/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] randomized search took 0.34 seconds\n",
      "[INFO] grid search accuracy: 76.62%\n",
      "[INFO] randomized search best parameters: {'n_neighbors': 13, 'metric': 'manhattan'}\n",
      "gird hyperparameter search wins with following params: {'metric': 'manhattan', 'n_neighbors': 15}\n"
     ]
    }
   ],
   "source": [
    "# Hypertune the KNN model using grid search and random search\n",
    "import time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# construct the set of hyperparameters to tune\n",
    "# distance between nearest neighbors metric to use\n",
    "params = {\"n_neighbors\": np.arange(1, 35, 2), \n",
    "          \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"]}\n",
    "\n",
    "print('Grid searching through following parameters: {}'.format(params))\n",
    "\n",
    "grid = GridSearchCV(knn, params)\n",
    "start = time.time()\n",
    "grid.fit(X, Y)\n",
    "\n",
    "# evaluate the best grid searched model on the testing data\n",
    "print(\"[INFO] grid search took {:.2f} seconds\".format(\n",
    "\ttime.time() - start))\n",
    "grid_acc = grid.score(X_test, y_test)\n",
    "print(\"[INFO] grid search accuracy: {:.2f}%\".format(grid_acc * 100))\n",
    "print(\"[INFO] grid search best parameters: {}\".format(\n",
    "\tgrid.best_params_))\n",
    "\n",
    "\n",
    "# Now highperparm search using random search method\n",
    "random_search = RandomizedSearchCV(knn, params)\n",
    "start = time.time()\n",
    "random_search.fit(X, y)\n",
    " \n",
    "# evaluate the best randomized searched model on the testing\n",
    "# data\n",
    "print(\"[INFO] randomized search took {:.2f} seconds\".format(\n",
    "\ttime.time() - start))\n",
    "random_acc = random_search.score(X_test, y_test)\n",
    "print(\"[INFO] grid search accuracy: {:.2f}%\".format(random_acc * 100))\n",
    "print(\"[INFO] randomized search best parameters: {}\".format(\n",
    "\trandom_search.best_params_))\n",
    "\n",
    "if grid_acc >= random_acc:\n",
    "    print('gird hyperparameter search wins with following params: {}'.format(grid.best_params_))\n",
    "else:\n",
    "    print('random hyperparameter search wins with following params: {}'.format(random_search.best_params_))   \n",
    "                                                                               \n",
    "                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6796650717703349, 0.7122351332877648, 0.7030587833219413, 0.7187115516062884, 0.7213773069036227, 0.7357142857142858, 0.7396274777853726, 0.7383116883116883, 0.7383458646616542, 0.7434723171565277, 0.7369446343130555, 0.7473684210526316, 0.7422077922077922, 0.7539131920710869, 0.7448051948051948, 0.7526144907723855, 0.7552973342447027, 0.7552802460697198, 0.7474709501025291, 0.7461893369788107, 0.7500683526999316, 0.7501196172248804, 0.7475222146274778, 0.7435919343814081, 0.7462064251537937, 0.7331681476418319, 0.7370813397129188, 0.7305365686944635, 0.7318523581681476, 0.7253588516746412]\n"
     ]
    }
   ],
   "source": [
    "#manually search through hyperparam space\n",
    "k_range = range(1, 31)\n",
    "\n",
    "# list of scores from k_range\n",
    "k_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in k_range:\n",
    "    # 2. run KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
